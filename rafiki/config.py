# Admin
MIN_SERVICE_PORT = 30000
MAX_SERVICE_PORT = 32767

# Inference
RUNNING_INFERENCE_WORKERS = 'running__inference_workers'
REQUEST_QUEUE = 'request_queue'
QFE_SLEEP = 0.25
INFERENCE_WORKER_SLEEP = 0.25
BATCH_SIZE = 32

